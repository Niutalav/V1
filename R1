Модуль №1
1.1 Предобработка данных и выделение значимых атрибутов
Вначале работы загружаем необходимые библиотеки и открываем файл с данными в виде таблицы DataFrame.

import pandas as pd
import numpy as np

df=pd.read_excel('Data/data.xlsx')
df.columns=["id", "no", "date", "origin_date", "recipient", "author", "content", "extra"]
df.set_index('id', inplace=True)
df.drop(df.index[:1], inplace=True)
df.head()

Исходя из предметной области, для будущей модели не нужны будут следующие данные: дата создания и отправления документа, номер документа в системе. Следовательно, мы оставляем только имя отправителя и получателя письма, краткое содержание и приложения к письмам, так как из них нужно будет извлечь дополнительную информацию.

df=df.drop(["no","date","origin_date"], axis=1)
# При повторном запуске ячейки без перекомпиляции, выведится ошибка, так как столбцы уже будут удалены в таблице после первого запуска.
df.shape

В результате получаем таблицу из 4967 строк и 5 столбцов.

1.2 Разбиение сложных атрибутов
В этом наборе данных сложными атрибутами являются значения всех полей, кроме целевого, поэтому необходимо будет обработать все: в разделе 1.2 будет обработано поле получателей, в разделе 1.3 поле отправителей, в разделе 1.4 частично будет затронуто поле содержания писем, в разделе 1.5 поле приложений к письмам.

Рассмотрим поле получателей:

df["recipient"].value_counts()

Поле хранит в себе значения, объединённые через спецсимвол "\n". Разделим их и преобразуем имена в более лёгкие, с помощью кода вид (из "Фамилия И.О." в "ФамилияИО"), и применим метод CountVectorizer библиотеки Scikit-learn для получения схожей с One-Hot матрицы, в которой столбцы - это все варианты адресатов, а значения в строках - 0 (не адресат) и 1 (адресат).

def processRecs(inp):
    inp=inp.replace(' ','')
    inp=inp.replace('.','')
    inp=inp.replace('\n',' ')
    return inp
df_r=df['recipient'].apply(processRecs)
df_r

from sklearn.feature_extraction.text import CountVectorizer as CV
CVr = CV()
rec_vecs=CVr.fit_transform(df_r)
CVr.get_feature_names()
# Преобразованные признаки

encoded_rec=pd.DataFrame(rec_vecs.toarray())
encoded_rec.columns=CVr.get_feature_names()
encoded_rec

На выходе получаем разрежённую матрицу из 281 столбца, которую можно будет присоединить к таблице с данными.

1.3 Дополнение недостающими данными
В информации об отправителе указаны: лицо, являющееся отправителем и организация, которую оно представляет. Если разбить поле на две части, то у нас будет больше информации об отправителе, а также это поможет выявить особо важные лица (будут встречены чаще других).

df['author'].value_counts()

Необходимо определить две функции: первая возвращает данные внутри скобок, а вторая возвращает данные до скобок. Затем потребуется сохранить столбец, обработанный обеими функциями, в две различных переменных.

def getBracketContent(inp):
    pos=inp.find('(')
    if (pos==-1):
        return inp
    return inp[pos+1:len(inp)-1]
def getBeforeBracket(inp):
    pos=inp.find('(')
    if (pos==-1):
        return inp
    if (inp.find('инистерство')==-1):
        return inp[:pos-1]
    return None
    
authors=df['author'].apply(getBeforeBracket)
authors.value_counts()

orgs=df['author'].apply(getBracketContent)
orgs.value_counts()

Мы получили два новых столбца для набора данных.

1.4 Формирование словарей данных
В этом разделе необходимо на основе кратких сведений о содержании писем построить словарь, данные которого могут быть использованы для предсказания target-переменной в дальнейшем, а также общее количество вхождений слов в документы.

Перед началом в столбце с текстами используем ранее задействованный класс CountVectorizer, указав в качестве стоп-слов часто используемые предлоги и различные непонятные символы из данных. Их мы вручную скопировали из данных, получившихся после первого прогона через векторайзер словаря.

content=df['content']
vectorizer=CV(stop_words=['00', 'г', 'гг', 'о', 'об', 'по', 'для', 'на', 'из', '0001', '001', '0020', '00321', '00366', '006', '01', '02', '03', '04', '043', '05', '05пр', '06', '062', '06g', '06пр', '07', '073', '074', '08', '09', '0900д', '10', '100', '1030', '104', '10584', '1065', '11', '1187', '119', '12', '120', '125', '1265', '13', '137', '14', '140', '141', '1426', '1455', '147', '1497', '15', '1551', '16', '17', '170315019', '170526050', '1723', '178', '17г', '18', '1849', '188', '189', '19', '1921', '194', '1942', '1968', '1f3', '1б', '1в', '1г', '1го', '1ж', '1с', '20', '200', '20118', '2015', '2016', '2016г', '2017', '2017г', '2017гг', '2018', '20185г', '2018г', '2019', '2019г', '2019гг', '202', '2020', '2021', '2021г', '2021гг', '2022', '2024', '2024г', '2025', '2030', '2035', '2073', '2075', '209', '20пр', '21', '210', '216', '2160', '217', '218', '22', '22017', '2220', '2225', '2249', '226', '228', '23', '230', '2323', '234', '2343', '24', '2429', '2494', '25', '2550', '2582', '2585', '26', '2603', '2604', '2605', '2606', '261', '262', '263', '265', '2679', '27', '273', '278', '279', '27февраля', '28', '286', '289', '29', '295', '298', '299', '2996818', '2а', '2б', '30', '300', '300579', '301', '30107', '306', '30пр', '31', '3100', '32', '321гс', '3259', '326', '328', '33', '332', '3372', '33с', '342', '349', '35', '3510', '36', '37', '372', '3751р', '37680', '38', '3857', '39', '3995', '3d', '3dld', '3и12', '3х', '404', '4060', '408', '42', '423', '425', '42548', '436', '437', '438', '45', '456', '46', '4600037832', '47', '486', '49', '4919п', '496', '50', '5000', '506', '51', '52', '52пр', '53', '58', '580', '58199', '59657', '598', '60', '61884', '625', '63', '63611', '638', '64392', '65', '652', '65935', '6629', '671', '677', '69', '690', '694', '695', '6981', '701', '708', '709', '70пр', '710', '7115', '73', '7412', '7493', '75', '750', '762', '77', '770400207282', '7721', '791', '807', '83', '839', '84', '846', '85', '869', '88', '89', '901', '91', '911', '9504', '976', '____', '__________', '____________', '_____________', '________________', '_________________', '____________________', '______________________', '________________________', '_________________________', '__________________________', '_____________________________', '___________________________________', '_____________________________________', '_______________________________________', '____________________________________________', '_____________________________________________', '_о', 'about'])
vectors=vectorizer.fit_transform(content)
vectorizer.vocabulary_

Ниже представлены столбцы (вхождения слов в описание писем 'индекс=строка') в виде разреженной матрицы, где значения ячейки - это количество вхождений слова в документ.

vecs_df=pd.DataFrame(vectors.toarray())
vecs_df.columns=vectorizer.get_feature_names()
vecs_df

В словаре получилось 5132 слова, это объясняется схожей тематикой текстов и малым количеством образцов.

1.5 Преобразование переадресаций
Во время переадресации в поле "приложения" указывается лицо, которому было перенаправлено письмо. Эту информацию необходимо вычленить. Проблему составляет наличие не нужных приложений и нестандартизированность записей в этом поле. Чтобы устранить её, необходимо обработать данное поле.

Создадим метод и применим его к столбцу с приложениями. Данный метод будет:
- пределять записи о переадресации по наличию слов "передан" и "направлено";
- стирать информацию о дате.

def filterExtras(inp):
    if (str(inp).lower().find('направлено')!=-1 or str(inp).lower().find('передан')!=-1):
        # Некоторые записи содержат ключевые слова, но не являются сведениями о переадресации конкретному лицу
        #Следующее условие их отфильтрует:
        if (str(inp.lower()).find('@')==-1 and str(inp.lower()).find('департамент')==-1 and str(inp.lower()).find('бухгалт')==-1 and str(inp.lower()).find('отдел')==-1 and str(inp).lower().find('академ')==-1 and str(inp).lower().find('адресат')==-1 and str(inp.lower()).find('суд')==-1):
            inp=inp.replace('1','')
            inp=inp.replace('2','')
            inp=inp.replace('3','')
            inp=inp.replace('4','')
            inp=inp.replace('5','')
            inp=inp.replace('6','')
            inp=inp.replace('7','')
            inp=inp.replace('8','')
            inp=inp.replace('9','')
            inp=inp.replace('0','')
            inp=inp.replace('- ','')
            inp=inp.replace('-','')
            inp=inp.replace('.. ','')
            inp=inp.replace(' ..','')
            inp=inp.replace('..','')
            inp=inp.replace('\n',' ')
            return inp
    return None
    
 Выведем значения, оставшиеся в этом столбце после частичной обработки:
 
df['extra']=df['extra'].apply(filterExtras)
df['extra'].value_counts()

1.6 Подготовка отчёта
Добавим данные, полученные в ходе сессии, в таблицу DataFrame и сохраним её в формате CSV.

data2=pd.concat([df, pd.DataFrame(encoded_rec), pd.DataFrame(authors), pd.DataFrame(orgs), pd.DataFrame(vecs_df)], axis=1)

data2.to_csv("data/data2.csv", sep=",")
data2.head()

Исходный файл data2.csv является конкатенацией исходных и преобразованных данных. Полученные данные сохраняются в наборе на случай потенциальной необходимости. Представленный ниже код также сохраняет аналогичный файл, но уже без необработанных столбцов под названием data_clear.csv. Оба файла составляют содержимое архива Data.zip.

pd.concat([pd.DataFrame(encoded_rec), pd.DataFrame(authors), pd.DataFrame(orgs), pd.DataFrame(vecs_df)], axis=1).to_csv("Data/data_clear.csv", sep=",")
